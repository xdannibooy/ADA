El objetivo de esta pr치ctica fue contrastar la teor칤a con el comportamiento real de los algoritmos al aumentar de manera significativa el tama침o de la entrada. Para ello, se analizaron cinco algoritmos cl치sicos, midiendo tanto su tiempo de ejecuci칩n como el consumo de memoria, con la intenci칩n de observar c칩mo influyen estos factores cuando el valor de 洧녵 crece.

En el caso de los algoritmos de b칰squeda, la diferencia entre enfoques es muy clara. La b칰squeda lineal representa la fuerza bruta, ya que revisa los elementos uno por uno hasta encontrar el valor deseado. Al probarla con un mill칩n de datos, el tiempo de ejecuci칩n fue aceptable, pero el crecimiento del tiempo es directamente proporcional al tama침o de la lista, lo que la vuelve poco pr치ctica en conjuntos de datos muy grandes. Por otro lado, la b칰squeda binaria, que funciona dividiendo el arreglo ordenado en mitades sucesivas, mostr칩 un desempe침o extremadamente superior. Para la misma cantidad de datos, el tiempo fue pr치cticamente instant치neo, lo que deja en evidencia el enorme impacto de trabajar con una complejidad logar칤tmica.

En cuanto a los algoritmos de ordenamiento, se compar칩 un m칠todo sencillo pero ineficiente contra uno mucho m치s optimizado. El ordenamiento burbuja result칩 ser muy lento, ya que compara repetidamente elementos adyacentes, lo que provoca un crecimiento cuadr치tico en el tiempo de ejecuci칩n. Incluso con una cantidad relativamente peque침a de elementos, el tiempo requerido fue considerable. Su principal ventaja es que casi no utiliza memoria adicional, ya que trabaja directamente sobre el arreglo original. En contraste, Merge Sort utiliza la estrategia de Divide y Vencer치s, logrando ordenar los datos en un tiempo mucho menor. El costo de esta mejora es el uso de memoria extra, ya que requiere arreglos auxiliares durante el proceso de combinaci칩n, lo que muestra claramente el intercambio entre velocidad y consumo de recursos.

Tambi칠n se analiz칩 el algoritmo recursivo para calcular la serie de Fibonacci, el cual es un buen ejemplo de c칩mo un c칩digo elegante puede tener un rendimiento muy pobre. Este algoritmo tiene una complejidad exponencial, ya que vuelve a calcular los mismos valores m칰ltiples veces. Aunque para valores peque침os funciona r치pidamente, al aumentar el tama침o de la entrada el tiempo de ejecuci칩n crece de manera descontrolada, llegando al punto de volverse impracticable para valores grandes.

En conclusi칩n, la pr치ctica dej칩 claro que no existe un algoritmo perfecto para todos los escenarios. La elecci칩n depende del problema, los recursos disponibles y las necesidades espec칤ficas. Si se busca rapidez en el ordenamiento, Merge Sort es una excelente opci칩n, aunque implique un mayor consumo de memoria. Si la memoria es muy limitada y el tiempo no es cr칤tico, un m칠todo simple como burbuja puede ser suficiente. Finalmente, cuando se realizan b칰squedas constantes en grandes vol칰menes de datos, vale la pena invertir tiempo en ordenar primero para poder aprovechar la eficiencia de la b칰squeda binaria.
